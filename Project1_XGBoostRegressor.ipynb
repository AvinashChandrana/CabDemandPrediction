{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 216, got 192\n",
      "  return f(*args, **kwds)\n",
      "D:\\Anaconda\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler,normalize\n",
    "from scipy.stats import spearmanr\n",
    "from scipy.stats import pearsonr\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import train_test_split,KFold,cross_val_score,RepeatedKFold\n",
    "from sklearn.metrics import r2_score,accuracy_score,mean_absolute_error,mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datapreprocess(df):\n",
    "    df['day']=df['datetime'].apply(lambda x:datetime.strptime(x,'%m/%d/%Y %H:%M').day)\n",
    "    df['month']=df['datetime'].apply(lambda x:datetime.strptime(x,'%m/%d/%Y %H:%M').month)\n",
    "    df['year']=df['datetime'].apply(lambda x:datetime.strptime(x,'%m/%d/%Y %H:%M').year)\n",
    "    df['hour']=df['datetime'].apply(lambda x:datetime.strptime(x,'%m/%d/%Y %H:%M').hour)\n",
    "    df.drop('datetime',axis=1,inplace=True)\n",
    "    #for col in ['season', 'holiday', 'workingday', 'month','hour','weather','day']:\n",
    "        #df[col] = df[col].astype('category')\n",
    "    weather_map={'Clear + Few clouds':'CF','Light Snow, Light Rain':'LSLR','Mist + Cloudy':'MC','Heavy Rain + Thunderstorm':'HRT'}\n",
    "    df['weather'] = df['weather'].apply(lambda x : weather_map.get(x.strip()))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def catgoricalencoding(df):\n",
    "    cols_for_label_encoding=['season','weather','year','month','hour','day']\n",
    "    dataset = pd.get_dummies(columns=cols_for_label_encoding, data=df)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_outlier(df):\n",
    "    features = df.columns\n",
    "    outliers  = []\n",
    "    for i, feature in enumerate(features):\n",
    "        if ( (df[feature].dtype == 'float64')):\n",
    "            # Calculate Q1 (25th percentile of the data) for the given feature\n",
    "            Q1 = np.percentile(df[feature], 25)\n",
    "            # Calculate Q3 (75th percentile of the data) for the given feature\n",
    "            Q3 = np.percentile(df[feature], 75)\n",
    "            # Use the interquartile range to calculate an outlier step\n",
    "            step = 1.5 * (Q3 - Q1)\n",
    "            feature_outliers = df[~((df[feature] >= Q1 - step) & (df[feature] <= Q3 + step))]\n",
    "            outliers.extend(list(feature_outliers.index.values))\n",
    "            print('Feature Name: {}, No. of outliers: {}\\n'.format(feature, len(feature_outliers.index)))\n",
    "    \n",
    "    multi_feature_outliers = (Counter(outliers) - Counter(set(outliers))).keys()\n",
    "    #print(outliers)\n",
    "    return outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv('train.csv')\n",
    "datapreprocess(train)\n",
    "train_laebl=pd.read_csv('train_label.csv',header=None)\n",
    "train_laebl.rename(columns={0:'Total_bookings'},inplace=True)\n",
    "train['Total_bookings']=train_laebl['Total_bookings']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Name: temp, No. of outliers: 0\n",
      "\n",
      "Feature Name: atemp, No. of outliers: 0\n",
      "\n",
      "Feature Name: windspeed, No. of outliers: 182\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "multi_feature_outliers = get_outlier(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=train.drop(train.index[list(multi_feature_outliers)]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=catgoricalencoding(train)\n",
    "\n",
    "Y=dataset['Total_bookings']\n",
    "\n",
    "dataset.drop(['atemp','weather_HRT','Total_bookings'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "def scaleData(dataset):\n",
    "    standardScaler = StandardScaler()\n",
    "    scaled_data = standardScaler.fit_transform(dataset[['humidity','temp','windspeed']])\n",
    "    scaled_data_df=pd.DataFrame(scaled_data,columns=['humidity','temp','windspeed'])\n",
    "    dataset[['humidity','temp','windspeed']] = scaled_data_df[['humidity','temp','windspeed']]\n",
    "    return dataset\n",
    "dataseta=scaleData(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test,y_train, y_test = train_test_split(dataset,Y,test_size=0.3,random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbRegressor = XGBRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:38:30] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
       "       importance_type='gain', learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=None, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " \n",
    "xgbRegressor.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8117821214840522"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgbRegressor.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict=xgbRegressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8128488814874986, 56.65761078047137)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test,y_predict) , mean_absolute_error(y_test,y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CHECK ON TEST DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "test=pd.read_csv('test.csv')\n",
    "test_label=pd.read_csv('test_label.csv',header=None)\n",
    "datapreprocess(test)\n",
    "test_data=catgoricalencoding(test)\n",
    "test_data.drop(['atemp'],axis=1,inplace=True)\n",
    "test_data=scaleData(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "bookng_predict_test=xgbRegressor.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8028050895990515, 58.12419634507379)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(test_label,bookng_predict_test) , mean_absolute_error(test_label,bookng_predict_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores=[]\n",
    "learning_rate=[]\n",
    "n_estimator=[]\n",
    "perforMetrics=pd.DataFrame(columns=['learningrate','nestimator','score','r2score','mse'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost Hyper parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score 0.9838035413662984\n"
     ]
    }
   ],
   "source": [
    "learningRate=[0.2]\n",
    "nestimator=2000\n",
    "for lr in learningRate:\n",
    "    xgb2=XGBRegressor(n_estimators= nestimator,objective='reg:squarederror',colsample_bytree=1,learning_rate=lr)\n",
    "    xgb2.fit(X_train,y_train)\n",
    "    score=xgb2.score(X_train,y_train)\n",
    "    print('score',score)\n",
    "    y_predict=xgb2.predict(X_test)\n",
    "    r2score,mse=r2_score(y_test,y_predict) , np.sqrt(mean_squared_error(y_test,y_predict))\n",
    "    perforMetrics = perforMetrics.append({'learningrate':lr,'nestimator':nestimator,'score':score,'r2score':r2score,'mse':mse},ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>learningrate</th>\n",
       "      <th>nestimator</th>\n",
       "      <th>score</th>\n",
       "      <th>r2score</th>\n",
       "      <th>mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.811782</td>\n",
       "      <td>0.812849</td>\n",
       "      <td>78.833363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1</td>\n",
       "      <td>300.0</td>\n",
       "      <td>0.902730</td>\n",
       "      <td>0.890433</td>\n",
       "      <td>60.318859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.1</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0.932705</td>\n",
       "      <td>0.915457</td>\n",
       "      <td>52.984842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.1</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.951984</td>\n",
       "      <td>0.924314</td>\n",
       "      <td>50.132894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.1</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.963112</td>\n",
       "      <td>0.929432</td>\n",
       "      <td>48.407903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.1</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>0.969703</td>\n",
       "      <td>0.931288</td>\n",
       "      <td>47.767379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.1</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>0.985929</td>\n",
       "      <td>0.931683</td>\n",
       "      <td>47.629837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.1</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>0.993676</td>\n",
       "      <td>0.927911</td>\n",
       "      <td>48.927106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.1</td>\n",
       "      <td>13000.0</td>\n",
       "      <td>0.995609</td>\n",
       "      <td>0.926478</td>\n",
       "      <td>49.410709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.2</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.971611</td>\n",
       "      <td>0.932149</td>\n",
       "      <td>47.466979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.3</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.979374</td>\n",
       "      <td>0.930978</td>\n",
       "      <td>47.874933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.4</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.983583</td>\n",
       "      <td>0.925558</td>\n",
       "      <td>49.719187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.5</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.986633</td>\n",
       "      <td>0.920678</td>\n",
       "      <td>51.322758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.2</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>0.983804</td>\n",
       "      <td>0.931677</td>\n",
       "      <td>47.631805</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   learningrate  nestimator     score   r2score        mse\n",
       "0           0.1       100.0  0.811782  0.812849  78.833363\n",
       "1           0.1       300.0  0.902730  0.890433  60.318859\n",
       "2           0.1       500.0  0.932705  0.915457  52.984842\n",
       "3           0.1      1000.0  0.951984  0.924314  50.132894\n",
       "4           0.1      1500.0  0.963112  0.929432  48.407903\n",
       "5           0.1      2000.0  0.969703  0.931288  47.767379\n",
       "6           0.1      5000.0  0.985929  0.931683  47.629837\n",
       "7           0.1     10000.0  0.993676  0.927911  48.927106\n",
       "8           0.1     13000.0  0.995609  0.926478  49.410709\n",
       "9           0.2      1000.0  0.971611  0.932149  47.466979\n",
       "10          0.3      1000.0  0.979374  0.930978  47.874933\n",
       "11          0.4      1000.0  0.983583  0.925558  49.719187\n",
       "12          0.5      1000.0  0.986633  0.920678  51.322758\n",
       "13          0.2      2000.0  0.983804  0.931677  47.631805"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perforMetrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
