{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler,normalize\n",
    "from scipy.stats import spearmanr\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split,KFold,cross_val_score,RepeatedKFold\n",
    "from sklearn.metrics import r2_score,accuracy_score,mean_absolute_error,mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datapreprocess(df):\n",
    "    df['day']=df['datetime'].apply(lambda x:datetime.strptime(x,'%m/%d/%Y %H:%M').day)\n",
    "    df['month']=df['datetime'].apply(lambda x:datetime.strptime(x,'%m/%d/%Y %H:%M').month)\n",
    "    df['year']=df['datetime'].apply(lambda x:datetime.strptime(x,'%m/%d/%Y %H:%M').year)\n",
    "    df['hour']=df['datetime'].apply(lambda x:datetime.strptime(x,'%m/%d/%Y %H:%M').hour)\n",
    "    df.drop('datetime',axis=1,inplace=True)\n",
    "    for col in ['season', 'holiday', 'workingday', 'month','hour','weather','day']:\n",
    "        df[col] = df[col].astype('category')\n",
    "    weather_map={'Clear + Few clouds':'CF','Light Snow, Light Rain':'LSLR','Mist + Cloudy':'MC','Heavy Rain + Thunderstorm':'HRT'}\n",
    "    df['weather'] = df['weather'].apply(lambda x : weather_map.get(x.strip()))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def catgoricalencoding(df):\n",
    "    cols_for_label_encoding=['season','weather','year','month','hour','day']\n",
    "    dataset = pd.get_dummies(columns=cols_for_label_encoding, data=df)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_outlier(df):\n",
    "    features = df.columns\n",
    "    outliers  = []\n",
    "    for i, feature in enumerate(features):\n",
    "        if ( (df[feature].dtype == 'float64')):\n",
    "            # Calculate Q1 (25th percentile of the data) for the given feature\n",
    "            Q1 = np.percentile(df[feature], 25)\n",
    "            # Calculate Q3 (75th percentile of the data) for the given feature\n",
    "            Q3 = np.percentile(df[feature], 75)\n",
    "            # Use the interquartile range to calculate an outlier step\n",
    "            step = 1.5 * (Q3 - Q1)\n",
    "            feature_outliers = df[~((df[feature] >= Q1 - step) & (df[feature] <= Q3 + step))]\n",
    "            outliers.extend(list(feature_outliers.index.values))\n",
    "            print('Feature Name: {}, No. of outliers: {}\\n'.format(feature, len(feature_outliers.index)))\n",
    "    \n",
    "    multi_feature_outliers = (Counter(outliers) - Counter(set(outliers))).keys()\n",
    "    #print(outliers)\n",
    "    return outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv('train.csv')\n",
    "datapreprocess(train)\n",
    "train_laebl=pd.read_csv('train_label.csv',header=None)\n",
    "train_laebl.rename(columns={0:'Total_bookings'},inplace=True)\n",
    "train['Total_bookings']=train_laebl['Total_bookings']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Name: temp, No. of outliers: 0\n",
      "\n",
      "Feature Name: atemp, No. of outliers: 0\n",
      "\n",
      "Feature Name: windspeed, No. of outliers: 182\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "multi_feature_outliers = get_outlier(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=train.drop(train.index[list(multi_feature_outliers)]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=catgoricalencoding(train)\n",
    "\n",
    "Y=dataset['Total_bookings']\n",
    "\n",
    "dataset.drop(['atemp','weather_HRT','Total_bookings'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "def scaleData(dataset):\n",
    "    standardScaler = StandardScaler()\n",
    "    scaled_data = standardScaler.fit_transform(dataset[['humidity','temp','windspeed']])\n",
    "    scaled_data_df=pd.DataFrame(scaled_data,columns=['humidity','temp','windspeed'])\n",
    "    dataset[['humidity','temp','windspeed']] = scaled_data_df[['humidity','temp','windspeed']]\n",
    "    return dataset\n",
    "dataseta=scaleData(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test,y_train, y_test = train_test_split(dataset,Y,test_size=0.3,random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
       "           oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor = RandomForestRegressor(n_estimators = 100, random_state = 0) \n",
    "\n",
    "regressor.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9867191556470022"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict=regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9047498575876904, 35.8492337763878)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test,y_predict) , mean_absolute_error(y_test,y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CHECK ON TEST DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "test=pd.read_csv('test.csv')\n",
    "test_label=pd.read_csv('test_label.csv',header=None)\n",
    "datapreprocess(test)\n",
    "test_data=catgoricalencoding(test)\n",
    "test_data.drop(['atemp'],axis=1,inplace=True)\n",
    "test_data=scaleData(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "bookng_predict_test=regressor.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9120482605935244, 35.13947658402204)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(test_label,bookng_predict_test) , mean_absolute_error(test_label,bookng_predict_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
